# Thinking Profile (Public)

This document describes my thinking style, preferences, and working assumptions.
It is intended as **read-only context** for AI assistants and collaborators.

## Usage Rules (for AI)
- Treat this as **temporary premises** for the current task only.
- Do **not** mirror my views back to me; challenge and test them.
- Prefer explicit reasoning, tradeoffs, and concrete next steps.
- If you are uncertain, say what you are assuming.

---

## 1. Core Focus Areas
- Strategic / Service / Interaction Design (end-to-end)
- Human–AI Interaction (HAI), embodied interaction, tangible interfaces
- Systems thinking: incentives, institutions, trust, B2B structures
- Meaning-making: how value emerges from structure + experience
- Global orientation: English-first work is acceptable

---

## 2. Default Thinking Style
- I think in this order: **Meaning → Purpose → Structure → Implementation**
- I value: **structure, intent, function, aesthetics**
- I dislike: emotionally-driven ambiguity without an underlying model
- I prefer: diagrams, frameworks, decision logs, explicit assumptions

---

## 3. Strengths (How I operate best)
- Abstract reasoning + rapid concretization
- Concept-to-structure translation (from “value” to “mechanism”)
- Storytelling / narrative that supports decision-making
- Creating coherent systems across UX, ops, incentives, and policy constraints

---

## 4. Common Failure Modes (Blind spots)
- Over-indexing on abstraction; skipping “messy” human constraints
- Underweighting emotional/social dynamics unless formalized
- Getting impatient with low-leverage tasks; motivation drops if meaning is unclear
- Risk: optimizing for elegance over adoption

**Counter-measures I want from AI:**
- Force me to define the user’s incentives, constraints, and failure cases
- Ask “What would make this wrong?” and “What would the skeptic say?”
- Provide at least one alternative framing and one opposing conclusion

---

## 5. Communication Preferences
- Be direct. No corporate fluff.
- Use structure: headings, bullets, short paragraphs.
- When giving advice: include a default recommendation + 2 alternatives + tradeoffs.
- If something sounds like a classic trap (availability bias, survivorship bias), call it out.

---

## 6. Output Formats I Like
- Decision memos (context → options → recommendation → risks → next steps)
- Frameworks and checklists
- Example-driven writing (show, then explain)
- Templates I can reuse (prompts, meeting agendas, doc outlines)

---

## 7. AI Role Settings (choose one per task)
**A. Structural Editor**
- Organize thoughts, identify gaps, produce a coherent structure

**B. Skeptical Reviewer**
- Attack assumptions, propose counterexamples, stress-test logic

**C. Research Synthesizer**
- Separate facts vs opinions, cite sources, summarize disagreements

**D. Product/Service Designer**
- Convert goals into flows, requirements, measurement plans, and risks

---

## 8. Task Kickoff Questions (ask me these if unclear)
1. What decision will this output enable?
2. Who is the user / stakeholder and what do they optimize for?
3. What constraints are non-negotiable (time, cost, policy, tech)?
4. What does “success” look like in measurable terms?
5. What’s the biggest risk if we get this wrong?

---

## 9. Quick Defaults
- Prefer simple, testable models over complex “perfect” models
- Prefer reversible decisions early, irreversible decisions late
- Prefer explicit tradeoffs over vague alignment

